## CLIP: Connecting Texts and Images

### Contrastive Language-Image Pre-training (CLIP)
### Contrastive Language-Image Pre-training (CLIP)

This is the paper [CLIP: Connecting Text and Images](https://arxiv.org/abs/2103.00020) by Alec Radford, Jong Wook Kim, Chris Hallacy, Aditya Ramesh, Gabriel Goh, Sandhini Agarwal, Girish Sastry, Amanda Askell, Pamela Mishkin, Jack Clark, Gretchen Krueger, Ilya Sutskever.

Official Website: [OpenAI - CLIP](https://openai.com/blog/clip/)

This paper is about a new neural network model called CLIP, which is a neural network model that can be used for zero-shot learning.

